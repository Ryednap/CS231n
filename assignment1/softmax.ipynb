{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:03:47.170537400Z",
     "start_time": "2023-06-03T07:03:46.751657100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on windows\n",
      "D:\\Deep Learning\\Stanford CS231n\\assignment1\\src\\datasets\n",
      "\n",
      "(deepenv) D:\\Deep Learning\\Stanford CS231n\\assignment1\\src\\datasets>IF NOT EXIST \"cifar-10-batches-py\" (\n",
      "certutil -urlcache -split -f \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" cifar-10-python.tar.gz  \n",
      " tar -xzvf cifar-10-python.tar.gz  \n",
      " del cifar-10-python.tar.gz \n",
      ") \n",
      "D:\\Deep Learning\\Stanford CS231n\\assignment1\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "sys.path.append('./src/')\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    print(\"Running on windows\")\n",
    "\n",
    "    %cd ./src/datasets\n",
    "    !cmd /C get_datasets.cmd\n",
    "    %cd ..\n",
    "else:\n",
    "    print(\"Running on Mac or linux\")\n",
    "\n",
    "    %cd ./src/datasets\n",
    "    !bash get_datastets.sh\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Run some setup for this notebook.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from src.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set the default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.ultratb import VerboseTB\n",
    "VerboseTB._tb_highlight = \"bg:#039dfc\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:06:14.533773200Z",
     "start_time": "2023-06-03T07:06:12.399805100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR-10 Data Loading and Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Load the raw CIFAR-10 data.\n",
    "cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "\n",
    "X_train = y_train = X_test = y_test = None\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:08:45.280990600Z",
     "start_time": "2023-06-03T07:08:41.785817100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, validation, and test sets. In addition, we will\n",
    "# create a small development set as a subset of the training set;\n",
    "# we can use this for development, so our code runs faster.\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 500\n",
    "\n",
    "# Our Validation set will be num_validation points from the original training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "# Our training set will be the first num_train points from the original training set.\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# We will also make a development set, which is a small subset of the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:11:14.607639500Z",
     "start_time": "2023-06-03T07:11:13.440759100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (49000, 3072)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Test data shape:  (10000, 3072)\n",
      "dev data shape:  (500, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:11:35.599602700Z",
     "start_time": "2023-06-03T07:11:34.800736800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.64189796 135.98173469 132.47391837 130.05569388 135.34804082\n",
      " 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3073) (1000, 3073) (10000, 3073) (500, 3073)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Mean centering, i.e., subtract the mean image\n",
    "\n",
    "# First: compute the image mean based on the training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "print(mean_image[: 10])  # print a few of the elements\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(mean_image.reshape((32, 32, 3)).astype('uint8'))  # visualize the mean image\n",
    "plt.show()\n",
    "\n",
    "# Second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "# Third: append the bias dimension of ones (i.e., bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix of W.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:11:41.936680200Z",
     "start_time": "2023-06-03T07:11:40.088755300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **`src/classifiers/softmax.py`**.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000000\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from src.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:19:42.918058400Z",
     "start_time": "2023-06-03T07:19:34.195423700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\textcolor{yellow}{\\textit Your Answer:}$ *Fill this in*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Deep Learning\\Stanford CS231n\\assignment1\\src\\gradient_check.py:70: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive) version\n",
    "# of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numerical gradient checking as a debugging tool.\n",
    "# The numerical gradient should be close to the analytic gradient.\n",
    "from src.gradient_check import  grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_check_sparse(f, W, grad, num_checks=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:22:07.931796900Z",
     "start_time": "2023-06-03T07:22:07.766760400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n",
      "numerical: 0.0 analytic: 0.0, relative_error: nan\n"
     ]
    }
   ],
   "source": [
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_check_sparse(f, W, grad, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:22:32.958556700Z",
     "start_time": "2023-06-03T07:22:32.888743900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 0.000000e+00 computed in 0.000000s\n",
      "vectorized loss: 0.000000e+00 computed in 0.000997s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from src.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:33:54.504717900Z",
     "start_time": "2023-06-03T07:33:54.393716300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful, you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "\n",
    "from src.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifier in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "# Provided as a reference. You may or may not want to change these hyperparameters\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "\n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on the test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\textcolor{yellow}{\\textit Your Answer:}$</br>\n",
    "\n",
    "\n",
    "</br>$\\textcolor{yellow}{\\textit Your Explanation:}$</br>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1, :]  # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)  # 2 per row\n",
    "\n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    w_img = 255.0 * (W[:, :, :, i].squeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(w_img.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
